{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e57ab144",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Coming soon ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "952d7070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules and packages\n",
    "import copy\n",
    "from pomegranate import *\n",
    "import matplotlib\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc, roc_auc_score,\n",
    "                             roc_curve, recall_score, classification_report, f1_score,\n",
    "                             precision_recall_fscore_support, precision_score, accuracy_score, matthews_corrcoef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "11130f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_model_from_json(filename=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Reads and returns model data from JSON file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "               Path to a saved model in JSON format\n",
    "    verbose  : bool, optional, default False\n",
    "               When True, prints progress to STDOUT\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    dict\n",
    "    JSON data as dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        modeldata = json.load(f)\n",
    "        #print(modeldata['edges'][2])\n",
    "        if verbose: print(\"Model read from:\", filename)\n",
    "        return(modeldata)\n",
    "\n",
    "\n",
    "\n",
    "def train_hmm(distribution=None, n_components=None, state_names=None, X=None, labels=None, algorithm=None, n_jobs=None):\n",
    "    \"\"\"\n",
    "    Helper function to train and bake Pomogranate HMM model. Returns baked Pomogranate HMM model.\n",
    "    Make sure you import the pomogranate package as-\n",
    "    from pomegranate import *\n",
    "    \n",
    "    This function uses (docstrings are appended below)-\n",
    "    pomogranate.HiddenMarkovModel.from_samples\n",
    "    pomogranate.HiddenMarkovModel.bake\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    # Example:\n",
    "    model = HiddenMarkovModel.from_samples(distribution=DiscreteDistribution, n_components=2,\n",
    "                                         state_names=['F','T'],\n",
    "                                         X=train_seqs, labels=train_labels,\n",
    "                                         algorithm='labeled',\n",
    "                                         n_jobs=2)\n",
    "    \"\"\"\n",
    "    \n",
    "    model = HiddenMarkovModel.from_samples(distribution=distribution, n_components=n_components,\n",
    "                                         state_names=state_names,\n",
    "                                         X=X, labels=labels,\n",
    "                                         algorithm=algorithm,\n",
    "                                         n_jobs=n_jobs)\n",
    "    model.bake()\n",
    "    return(model)\n",
    "# Append docstring\n",
    "train_hmm.__doc__ += \"\\nHiddenMarkovModel.from_samples\\n\\n\" + HiddenMarkovModel.from_samples.__doc__\n",
    "train_hmm.__doc__ += \"\\n\\nHiddenMarkovModel.bake\\n\\n\" + HiddenMarkovModel.bake.__doc__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "8c8375f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def validate(model=None, states=None, true_seqs=None, true_labels=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Validates true sequences and labels using a given model.\n",
    "    Designed only for two state models. Thus the states must be two in number.\n",
    "    The first state in the 'states' list is considered 0 and the second state is considered 1. \n",
    "    Calculates and returns validation metrics (see below).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model            : Pomogranate HMM model object, default None\n",
    "    states           : list, default None\n",
    "                       List of states (str) used in the sequences. Must be two in number.\n",
    "                       The function is designed only for two state models.\n",
    "                       The first state in the 'states' list is considered 0 and the second state \n",
    "                       is considered 1.\n",
    "    true_seqs        : Pandas data series, default None\n",
    "                       Values are sequences (strings) of characters for which labels are to be \n",
    "                       predicted using the model.\n",
    "    true_labels      : Pandas data series, default None\n",
    "                       Values are sequences (strings) of characters representing labels or states\n",
    "                       that will be used to compare with the predicted labels or states.\n",
    "    verbose          : bool, optional, default False\n",
    "                       When True, prints information to STDOUT\n",
    "\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    dict\n",
    "    Dictionary model validation metrics-\n",
    "    ConfusionMatrix, Recall, Precision, Accuracy, MCC, AUC and F1score\n",
    "    \"\"\"\n",
    "    \n",
    "    # Confirm that number of states are two\n",
    "    try:\n",
    "        assert(len(states)==2)\n",
    "    except AssertionError:\n",
    "        print(\"Error: Number states is not equal to 2.\")\n",
    "        return({\"ConfusionMatrix\":None,\"Recall\":None,\"Precision\":None,\"Accuracy\":None,\"MCC\":None,\"AUC\":None,\"F1score\":None})\n",
    "\n",
    "    y_true_all = []\n",
    "    y_pred_all = []\n",
    "    F_predictedAs_T_fraction = []\n",
    "    T_predictedAs_F_fraction = []\n",
    "    recall = []\n",
    "    precision = []\n",
    "    accuracy = []\n",
    "    f1 = []\n",
    "    for i in true_seqs.index:\n",
    "        y_true = [int(ch==states[1]) for ch in true_labels[i]] # inserts 0 for first state and 1 for second state\n",
    "        y_true_all += copy.copy(y_true)\n",
    "        y_pred = model.predict(list(true_seqs[i]))\n",
    "        y_pred_all += copy.copy(y_pred)\n",
    "        #print([int(ch=='T') for ch in true_labels[i]])\n",
    "        #print(\"\".join([states[i] for i in pred_labels]))\n",
    "        #print(pred_labels)\n",
    "        #print(i,\"\\n\",true_seqs[i],\"\\n\",true_labels[i],\"\\n\",\"\".join([states[i] for i in y_pred]))\n",
    "    \n",
    "    \"\"\"\n",
    "    print(len(y_true_all),len(y_pred_all))\n",
    "    print()\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true_all,y_pred_all))\n",
    "    print(\"Recall:\",recall_score(y_true_all,y_pred_all))\n",
    "    print(\"Precision:\",precision_score(y_true_all,y_pred_all))\n",
    "    print(\"Accuracy:\",accuracy_score(y_true_all,y_pred_all))\n",
    "    print(\"MCC:\",matthews_corrcoef(y_true_all,y_pred_all))\n",
    "    print(\"AUC:\",roc_auc_score(y_true_all,y_pred_all))\n",
    "    print(\"F1 score:\",f1_score(y_true_all,y_pred_all))\n",
    "    \"\"\"\n",
    "    return {\"ConfusionMatrix\":confusion_matrix(y_true_all,y_pred_all),\n",
    "                    \"Recall\":recall_score(y_true_all,y_pred_all),\n",
    "                    \"Precision\":precision_score(y_true_all,y_pred_all),\n",
    "                    \"Accuracy\":accuracy_score(y_true_all,y_pred_all),\n",
    "                    \"MCC\":matthews_corrcoef(y_true_all,y_pred_all),\n",
    "                    \"AUC\":roc_auc_score(y_true_all,y_pred_all),\n",
    "                    \"F1score\":f1_score(y_true_all,y_pred_all)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "1112a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary functions\n",
    "def histogram1d(data=None, binsize=None, xmin=None, xmax=None):\n",
    "    if xmin is None and xmax is None:\n",
    "        xmin = min(data)\n",
    "        xmax = max(data)\n",
    "    xedges = np.arange(xmin,xmax+binsize,binsize)\n",
    "    H, xe = np.histogram(data,bins=xedges)\n",
    "    #print(\"Value range:\",xmin,xmax)\n",
    "    return(H,xe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "8c0ed8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(seq=None,translation_dict=None):\n",
    "    \"\"\"\n",
    "    Translates sequence of characters based on the provided translation dictionary.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    seq              : str, default None\n",
    "                       Sequence of characters to be translated\n",
    "    translation_dict : dict, default None\n",
    "                       Dictionary to use for translation of 'seq'.\n",
    "                       All characters in the input sequence must be present in the keys of the translation dictionary.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    str\n",
    "    Translated sequence\n",
    "    \n",
    "    \"\"\"\n",
    "    if translation_dict:\n",
    "        return(\"\".join([translation_dict[ch] for ch in seq]))\n",
    "    else:\n",
    "        return(\"\".join([ch for ch in seq]))\n",
    "\n",
    "    \n",
    "def get_seq_dictionary(datadir=None, filelist=None, header_regex_str=None, translation_dict=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Translates sequence of characters based on the provided translation dictionary.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    datadir          : str, default None\n",
    "                       Path to directory that contains files containing sequences in FASTA format (shown below).\n",
    "                       > sequence name 1\n",
    "                       ALKDSFJOSDIFUSDCOSDNWEIFUCSNDJ\n",
    "                       > sequence name 2\n",
    "                       OSIFJODSICVJIWDCNSIDCIWF\n",
    "                       > sequence name 3\n",
    "                       LAKSDJFOWIEROSICJOISFJLSKDFD\n",
    "    filelist         : list, default None\n",
    "                       List of file names (str) to read from 'datadir'\n",
    "    header_regex_str : str, default None\n",
    "                       The header is parsed according to this regex string and first match group is used at the key.\n",
    "                       If None then the full header line (except the last new line) is used as the key.\n",
    "    translation_dict : dict, default None\n",
    "                       Dictionary to use for translation of 'seq'.\n",
    "                       All characters in the input sequence must be present in the keys of the translation dictionary.\n",
    "    verbose          : bool, optional, default False\n",
    "                       When True, prints information to STDOUT\n",
    "\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    dict\n",
    "    Dictionary of sequences.\n",
    "    Keys are sequence headers read from FASTA formatted sequences.\n",
    "    Values are sequences translated using 'traslation_dict'.\n",
    "    If a duplicate sequence header is found then it is replaced by the one found later.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if header_regex_str is None:\n",
    "        header_regex_str = '(.*)\\n'\n",
    "\n",
    "    seq = {}\n",
    "    for filename in filelist:\n",
    "        try:\n",
    "            f = open(datadir+\"/\"+filename,'r')\n",
    "        except:\n",
    "            if verbose:\n",
    "                print(\"Error while opening file\", datadir+\"/\"+filename)\n",
    "            continue\n",
    "\n",
    "        for line in f.readlines():\n",
    "            if line.startswith('>'):\n",
    "                matchObj = re.match(header_regex_str,line,re.S)\n",
    "                header = matchObj.group(1)\n",
    "                seq[header] = \"\"\n",
    "            else:\n",
    "                seq[header] += translate(line.replace('\\n',''),translation_dict=translation_dict)\n",
    "        f.close()\n",
    "    return(seq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03521191",
   "metadata": {},
   "source": [
    "<h3>Define input variables</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "9e8b6133",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data directory\n",
    "datadir = \"pakTailSeqs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "98ba618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### List of tail and full length sequence files\n",
    "\n",
    "tail_seq_files = [\n",
    "#'adk_cdhit90_tails.fasta',\n",
    "#'hbha_cdhit90_tails.fasta',\n",
    "#'hc1_cdhit90_tails.fasta',\n",
    "#'hc2_cdhit90_tails.fasta',\n",
    "'hu_cdhit90_tails.fasta'\n",
    "#'ku_cdhit90_tails.fasta'\n",
    "#'l22_cdhit90_tails.fasta',\n",
    "#'rbr_cdhit90_tails.fasta'#? Manually identified tails are probably not correct PAK tails.\n",
    "#'sig_cdhit90_tails.fasta'#? Manually identified tails are probably not correct PAK tails.\n",
    "#'tig_cdhit90_tails.fasta',\n",
    "#'topo1_cdhit90_tails.fasta',\n",
    "#'topo3_cdhit90_tails.fasta'\n",
    "]\n",
    "\n",
    "full_seq_files = [\n",
    "#'adk_cdhit90.fasta',\n",
    "#'hbha_cdhit90.fasta',\n",
    "#'hc1_cdhit90.fasta',\n",
    "#'hc2_cdhit90.fasta',\n",
    "'hu_cdhit90.fasta'\n",
    "#'ku_cdhit90.fasta'\n",
    "#'l22_cdhit90.fasta',\n",
    "#'rbr_cdhit90.fasta'#? Manually identified tails are probably not correct PAK tails.\n",
    "#'sig_cdhit90.fasta'#? Manually identified tails are probably not correct PAK tails.\n",
    "#'tig_cdhit90.fasta',\n",
    "#'topo1_cdhit90.fasta',\n",
    "#'topo3_cdhit90.fasta'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1255b8",
   "metadata": {},
   "source": [
    "### Define observed states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "2678b533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define observed states for HMM\n",
    "#\n",
    "# Amino acid residue codes (i.e. observed states)\n",
    "# Amino acids P, A, K and T are most common in manually identified PAK-tails in HU proteins.\n",
    "# Below are the frequencies.\n",
    "# A 0.329\n",
    "# K 0.264\n",
    "# T 0.184\n",
    "# P 0.067\n",
    "# Proline is distinctly infrequent compared to A, K and T,\n",
    "# but PAK-tail analysis described by Khare et al* indicates its importance in the dynamics and conformation of the tails.\n",
    "# Hence Proline is considered as a separate category.\n",
    "#\n",
    "# Categories: This categorization will help in discriminating P, A, K, T and other amino acids (O).\n",
    "# Taking P, A, K and T in one group leads to poly-A or poly-P stretches to be labeled as PAK-tails.\n",
    "# Keeping P, A, K and T as separate categories might help in learning their combinations.\n",
    "# Categories are assigned as follows.\n",
    "# P\n",
    "# A\n",
    "# K\n",
    "# T\n",
    "# O: OTHERS (D,E,G,A,V,L,I,M,C,N,Q,F,Y,W,P,S,T)\n",
    "#\n",
    "# *Conformational heterogeneity in tails of DNA-binding proteins is augmented by proline containing repeats; Khare et al 2017\n",
    "\n",
    "# Amino acid code single letter\n",
    "aa_code1 = ['A','C','D','E','F','G','H','I','K','L','M','N','P','Q','R','S','T','V','W','X','Y']\n",
    "\n",
    "# Amino acid categories i.e. the observed states for HMM\n",
    "aa_code_cat = ['P','A','K','T','O']\n",
    "\n",
    "# Amino acid category mapping dictionary\n",
    "aa_code_cat_dict = {'P':'P',\n",
    "                     'A':'A',\n",
    "                     'K':'K',\n",
    "                     'T':'T',\n",
    "                     'C':'O', 'D':'O', 'E':'O', 'F':'O', 'G':'O', 'H':'O', 'I':'O', 'L':'O',\n",
    "                     'M':'O', 'N':'O', 'Q':'O', 'R':'O', 'S':'O', 'V':'O', 'W':'O', 'X':'O', 'Y':'O'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd13663",
   "metadata": {},
   "source": [
    "### Define hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "d3e66746",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define hidden states for HMM. Two states here, Folded and Tail.\n",
    "states = ['F','T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "315925ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of hidden states for HMM\n",
    "n_states = len(states)\n",
    "\n",
    "# Numger of observed staets for HMM\n",
    "n_states_observed = len(aa_code_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb070e2a",
   "metadata": {},
   "source": [
    "<h3>Prepare input data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "a59d2f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tail sequences: 59 \n",
      "Number of all (full) sequences: 1353\n"
     ]
    }
   ],
   "source": [
    "seq_tail = get_seq_dictionary(datadir=datadir, filelist=tail_seq_files, header_regex_str='>(.+).*\\n', translation_dict=aa_code_cat_dict, verbose=True)\n",
    "seq_full = get_seq_dictionary(datadir=datadir, filelist=full_seq_files, header_regex_str='>(.+?)\\s.*\\n', translation_dict=aa_code_cat_dict, verbose=True)\n",
    "\n",
    "print(\"Number of tail sequences:\",len(seq_tail),\"\\nNumber of all (full) sequences:\",len(seq_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "47c6881b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tail seqs: (59,) \n",
      "Full seqs: (1353,)\n",
      "tr|A0A0T9L3R4|A0A0T9L3R4_MYCTX    AOOAPAOOOOPAAOPOAAOTOAOOPOAPAAKKAKOAKOOKOOKOOK...\n",
      "tr|A0A077M8Y5|A0A077M8Y5_9MICO    AOPOKOPKTAOTOOOAPAOOATATATKAAAKKTTTAKOTTAAKKTT...\n",
      "tr|W7SIK7|W7SIK7_9PSEU            OOTOKOPOOTAAAAKPAAOPAAKATAKOOATKPAOOATAAKATATO...\n",
      "tr|H0K1H8|H0K1H8_9PSEU            OOAKKOPKATTTKOOTTOTOOTTAOTAKTAATOPTOTOOTTOOTOA...\n",
      "tr|A0A0H5CLV3|A0A0H5CLV3_9PSEU    OOTKKOPKOAATOPAAAAPAAOATATOTTATOATTATOTTOAAAOT...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "### Convert data into Pandas objects\n",
    "tail = pd.Series(seq_tail)\n",
    "full = pd.Series(seq_full)\n",
    "print(\"Tail seqs:\",tail.shape,\"\\nFull seqs:\",full.shape)\n",
    "print(tail.head())\n",
    "#print(full.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "a5f3ecff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: Index(['FULL', 'TAIL', 'FULLLEN', 'TAILLEN', 'FOLDLEN', 'FULLLABELS',\n",
      "       'HEADER'],\n",
      "      dtype='object')\n",
      "Shape (all seqs): (1353, 7)\n",
      "Shape (tail seqs): (59, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FULL</th>\n",
       "      <th>TAIL</th>\n",
       "      <th>FULLLEN</th>\n",
       "      <th>TAILLEN</th>\n",
       "      <th>FOLDLEN</th>\n",
       "      <th>FULLLABELS</th>\n",
       "      <th>HEADER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OOKAOOOOOOTOKOOOOOOOATAAOOOOOOTOOOAOOKOOOOTOTO...</td>\n",
       "      <td>AOAOOOPOOOPAOKOOOATOAAKKAAOKKAPOKKAOAKKAATKAPA...</td>\n",
       "      <td>200</td>\n",
       "      <td>111</td>\n",
       "      <td>89</td>\n",
       "      <td>FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...</td>\n",
       "      <td>sp|O33125|DBH_MYCLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OOKOOOOOAOAOKAOOTKOOAAOAOOAOOOOOOAOOKOKOOOOOAO...</td>\n",
       "      <td></td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...</td>\n",
       "      <td>sp|P02348|DBH5_RHILE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OOKOOOOOAOAAOAOOPKAOAOOAOOAOOOOOTOAOKAOOOOOOOO...</td>\n",
       "      <td></td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...</td>\n",
       "      <td>sp|P05384|DBHB_PSEAE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OOKOOOOOKOAAOAOOOKAAAOOAOOAOOAOOTOOOKOOOOOAOOO...</td>\n",
       "      <td></td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...</td>\n",
       "      <td>sp|P0A1R8|DBHB_SALTY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OTKKOOOOOOAKKAOAKKKOOKOOOOTOOOTOTOAOAKOOKOOOOO...</td>\n",
       "      <td></td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...</td>\n",
       "      <td>sp|P36206|DBH_THEMA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                FULL  \\\n",
       "0  OOKAOOOOOOTOKOOOOOOOATAAOOOOOOTOOOAOOKOOOOTOTO...   \n",
       "1  OOKOOOOOAOAOKAOOTKOOAAOAOOAOOOOOOAOOKOKOOOOOAO...   \n",
       "2  OOKOOOOOAOAAOAOOPKAOAOOAOOAOOOOOTOAOKAOOOOOOOO...   \n",
       "3  OOKOOOOOKOAAOAOOOKAAAOOAOOAOOAOOTOOOKOOOOOAOOO...   \n",
       "4  OTKKOOOOOOAKKAOAKKKOOKOOOOTOOOTOTOAOAKOOKOOOOO...   \n",
       "\n",
       "                                                TAIL  FULLLEN  TAILLEN  \\\n",
       "0  AOAOOOPOOOPAOKOOOATOAAKKAAOKKAPOKKAOAKKAATKAPA...      200      111   \n",
       "1                                                          91        0   \n",
       "2                                                          90        0   \n",
       "3                                                          90        0   \n",
       "4                                                          90        0   \n",
       "\n",
       "   FOLDLEN                                         FULLLABELS  \\\n",
       "0       89  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...   \n",
       "1       91  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...   \n",
       "2       90  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...   \n",
       "3       90  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...   \n",
       "4       90  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...   \n",
       "\n",
       "                 HEADER  \n",
       "0   sp|O33125|DBH_MYCLE  \n",
       "1  sp|P02348|DBH5_RHILE  \n",
       "2  sp|P05384|DBHB_PSEAE  \n",
       "3  sp|P0A1R8|DBHB_SALTY  \n",
       "4   sp|P36206|DBH_THEMA  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Make dataframe containing tails and full length sequences\n",
    "### Create columns containing label sequences\n",
    "df = pd.concat([full, tail], axis=1, sort=True)\n",
    "\n",
    "df.columns=['FULL','TAIL']\n",
    "df = df.replace(np.nan, '', regex=True)\n",
    "df['FULLLEN'] = df['FULL'].str.len()\n",
    "df['TAILLEN'] = df['TAIL'].str.len()\n",
    "df['FOLDLEN'] = df['FULLLEN'] - df['TAILLEN']\n",
    "#df['FoldLabels'] = df['FoldLen'].apply(lambda x: 'F'*x)\n",
    "#df['TailLabels'] = df['TailLen'].apply(lambda x: 'T'*x)\n",
    "df['FULLLABELS'] = df['FOLDLEN'].apply(lambda x: 'F'*x) + df['TAILLEN'].apply(lambda x: 'T'*x)\n",
    "#df['Tally'] = df['FullLabels'].str.len()\n",
    "#df.to_csv(path_or_buf=\"test.csv\",sep=\",\")\n",
    "\n",
    "df['HEADER'] = df.index\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Columns:\",df.columns)\n",
    "print(\"Shape (all seqs):\",df.shape)\n",
    "#print(df[df['Tail'] != ''].head())\n",
    "print(\"Shape (tail seqs):\",df[df['TAIL'] != ''].shape)\n",
    "df.head()\n",
    "#df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "2dfd6e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668     OOKAOOOOAOAOKAOOTOOOAKKAOOAOOAOOOOAOKAOOTOOOOO...\n",
      "334     OOKKOOAOOOAOOOOTOKAOOOOOOOOOOOKOOOTOTKOOOOOOAO...\n",
      "17      OOKOOOOOOOATTAOOOKTOATAAOOAOOTOOOOTOAOOOOOAOTO...\n",
      "1062    OOKAOOOOAOAOKOOOOOOAAOAOOOOOOAOOOAOOAOOOOOOTOO...\n",
      "740     OOKOOOOOAOAAOAOOOKAOAKKAOOAOOTOOTOAOKAOOKOOOOO...\n",
      "Name: FULL, dtype: object\n",
      "390    OTTTPPOOOPTOOOOAAOKOOOPOKTOAOOOOOOOKOOOOAKKPOA...\n",
      "789    OOTOOKOOOKKOOKTOOOAOOTOOOOOOKOAAOKTOTKAOAOKAOO...\n",
      "126    OOKTOOOOOOOTKAOOOKAOAOOAOOAOOOAOTTTOKOKOTOTOOO...\n",
      "542    OOKTOOOOAOAOKOOOOKKOATKAOOOOOOTOOOOOKOOOKOOOOO...\n",
      "553    OOKTOOOOKOOOOTOOTKKOAOAAOOAOOOAOTOAOKOOOKOOOOO...\n",
      "Name: FULL, dtype: object\n",
      "(811,) (542,)\n",
      "(811,) (542,)\n",
      "# of seqs with tails in train_seqs 36\n",
      "# of seqs with tails in test_seqs 23\n",
      "\n",
      "The following ratios should be as similar as possible (Adjust random seed accordingly):\n",
      "Train seqs/tails in train seqs = 22.52777777777778\n",
      "Test seqs/tails in test seqs = 23.565217391304348\n"
     ]
    }
   ],
   "source": [
    "### Split input data into train and test sets\n",
    "\n",
    "### Standard way of train test splitting:\n",
    "### X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "### We consider amino acid sequences as X and label sqeuences as y\n",
    "\n",
    "train_seqs, test_seqs, train_labels, test_labels = train_test_split(df.FULL, df.FULLLABELS, test_size=0.4, random_state=61)\n",
    "\n",
    "print(train_seqs.head())\n",
    "print(test_seqs.head())\n",
    "print(train_seqs.shape, test_seqs.shape)\n",
    "print(train_labels.shape, test_labels.shape)\n",
    "#print(train_seqs.head())\n",
    "#print(train_labels.head())\n",
    "print(\"# of seqs with tails in train_seqs\",sum(df.loc[train_seqs.index].TAILLEN > 0))\n",
    "print(\"# of seqs with tails in test_seqs\",sum(df.loc[test_seqs.index].TAILLEN > 0))\n",
    "print(\"\\nThe following ratios should be as similar as possible (Adjust random seed accordingly):\")\n",
    "print(\"Train seqs/tails in train seqs =\",train_seqs.shape[0]/sum(df.loc[train_seqs.index].TAILLEN > 0))\n",
    "print(\"Test seqs/tails in test seqs =\",test_seqs.shape[0]/sum(df.loc[test_seqs.index].TAILLEN > 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a2c7bd",
   "metadata": {},
   "source": [
    "<h3>Build model on train set</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "464d7ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.99520333e-01 4.79667431e-04 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.00000000e-01 5.00000000e-01 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "### Build first model and write to file as json object\n",
    "model_0 = train_hmm(distribution=DiscreteDistribution,\n",
    "                    n_components=len(states),\n",
    "                    state_names=states,\n",
    "                    X=[list(s) for s in list(train_seqs)], # Needs sequences as lists of characters\n",
    "                    labels=[list(s) for s in list(train_labels)], # Needs sequences as lists of characters\n",
    "                    algorithm='labeled',\n",
    "                    n_jobs=2)\n",
    "\n",
    "model_0_json = model_0.to_json()\n",
    "with open(\"model_0.json\",'w') as f:\n",
    "    f.write(model_0_json)\n",
    "\n",
    "#print(model_1)\n",
    "print(model_0.dense_transition_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b60cc3f",
   "metadata": {},
   "source": [
    "<h3>Model validation with grid search on transition probability matrix (Takes long time)</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "f24c921d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9995203325694185 0.0004796674305814636 0.0 1.0\n",
      "FF_start = 0.9995203325694185         FF_end = 0.69\n",
      "TT_start = 0.999         TT_end = 0.79\n",
      "Step = -0.2\n"
     ]
    }
   ],
   "source": [
    "### Grid search on transition probability matrix is needed because there is no T to F transition in this data.\n",
    "### However, there could be T to F transition in new data.\n",
    "### Therefore, T to F transition probability has to be non-zero.\n",
    "### Grid search will allow to select a good enough model with non-zero T to F transition probability.\n",
    "\n",
    "### Also, the selected model at this stage has to be very precise in identifying tails.\n",
    "### Since tails are encoded as 1 and folded region as 0,\n",
    "### the calculated precision, TP/(TP+FP), gives precision of identifying tails.\n",
    "### Choose model with highest precision.\n",
    "\n",
    "### Read model from json file\n",
    "\n",
    "with open(\"model_0_PAKTO.json\", 'r') as f:\n",
    "    model_json = json.load(f)\n",
    "\n",
    "for a in model_json['edges']:\n",
    "    if (a[0],a[1]) == (0,0):\n",
    "        FF = a[2]\n",
    "    elif (a[0],a[1]) == (0,1):\n",
    "        FT = a[2]\n",
    "    elif (a[0],a[1]) == (1,0):\n",
    "        TF = a[2]\n",
    "    elif (a[0],a[1]) == (1,1):\n",
    "        TT = a[2]\n",
    "print(FF,FT,TF,TT)\n",
    "\n",
    "### Set state transition probabilites for grid search\n",
    "### Run this block multiple times adjusting/refining the size of the grid\n",
    "FF_start = model_json['edges'][2][2]\n",
    "FF_end = 0.69# 0.89\n",
    "print(\"FF_start =\",FF_start,\"        FF_end =\",FF_end)\n",
    "TT_start = 0.999\n",
    "TT_end = 0.79# 0.001\n",
    "print(\"TT_start =\",TT_start,\"        TT_end =\",TT_end)\n",
    "step = -0.2#-0.01# 0.1 # Keep the stepsize smaller. Bigger value is set here for testing purpose.\n",
    "print(\"Step =\",step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "8516ab31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search finished.\n"
     ]
    }
   ],
   "source": [
    "### Grid search for all combinations of FF&FT and TF&TT\n",
    "### Change file name for output of grid search each time\n",
    "This block takes long time to run. Uncommented line to avoid executing this block accedentally.\n",
    "\n",
    "f = open(\"gridsearch_2_PAKTO.csv\",'w')\n",
    "f.write(\"FF,FT,TF,TT,Recall,Precision,Accuracy,MCC,AUC,F1score\\n\")\n",
    "for FF in np.arange(FF_start,FF_end,step):\n",
    "    FT = 1.0 - FF\n",
    "    for TT in np.arange(TT_start,TT_end,step):\n",
    "        TF = 1.0 - TT\n",
    "        #print('{:.5f}'.format(FF), '{:.5f}'.format(FT))\n",
    "        #print('{:.5f}'.format(TF), '{:.5f}'.format(TT))\n",
    "        #print()\n",
    "        \n",
    "        #model_json['edges'][2][2] = FF\n",
    "        #model_json['edges'][3][2] = FT\n",
    "        #model_json['edges'][4][2] = TF\n",
    "        #model_json['edges'][5][2] = TT\n",
    "\n",
    "        cnt = 0\n",
    "        for a in model_json['edges']:\n",
    "            if (a[0],a[1]) == (0,0):\n",
    "                model_json['edges'][cnt][2] = FF\n",
    "            elif (a[0],a[1]) == (0,1):\n",
    "                model_json['edges'][cnt][2] = FT\n",
    "            elif (a[0],a[1]) == (1,0):\n",
    "                model_json['edges'][cnt][2] = TF\n",
    "            elif (a[0],a[1]) == (1,1):\n",
    "                model_json['edges'][cnt][2] = TT\n",
    "            cnt += 1\n",
    "\n",
    "        model = HiddenMarkovModel.from_json(json.dumps(model_json, indent=4))\n",
    "        val = validate(model=model, states=states, true_seqs=test_seqs, true_labels=test_labels)\n",
    "        f.write(\",\".join([str(s) for s in [FF, FT, TF, TT,\n",
    "                                           val[\"Recall\"], val[\"Precision\"],                                            \n",
    "                                           val[\"Accuracy\"], val[\"MCC\"],\n",
    "                                           val[\"AUC\"], val[\"F1score\"]]]) + \"\\n\")\n",
    "f.close()\n",
    "print(\"Grid search finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "b86a7d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inspection of the grid search output file suggests following state transition\n",
    "### probabilities to be satisfactory for good precision.\n",
    "### Generate model with selected state transition probabilities.\n",
    "FF = 0.9995203326\n",
    "FT = 0.0004796674\n",
    "TF = 0.201\n",
    "TT = 0.799\n",
    "\n",
    "# Load the first model that was created to get the structure of the model.\n",
    "with open(\"model_0.json\", 'r') as f:\n",
    "    model_json = json.load(f)\n",
    "\n",
    "# Update the state transition probabilities with the ones we want.\n",
    "cnt = 0\n",
    "for a in model_json['edges']:\n",
    "    if (a[0],a[1]) == (0,0):\n",
    "        model_json['edges'][cnt][2] = FF\n",
    "    elif (a[0],a[1]) == (0,1):\n",
    "        model_json['edges'][cnt][2] = FT\n",
    "    elif (a[0],a[1]) == (1,0):\n",
    "        model_json['edges'][cnt][2] = TF\n",
    "    elif (a[0],a[1]) == (1,1):\n",
    "        model_json['edges'][cnt][2] = TT\n",
    "    cnt += 1\n",
    "\n",
    "# Create the model object from the json string and write a new json model file.\n",
    "# Creating the model object shouldn't be necessary and just writing json string to file should be enough.\n",
    "# But creating a model object confirms that we edited the json file with new probabilities correctly.\n",
    "model = HiddenMarkovModel.from_json(json.dumps(model_json, indent=4))\n",
    "with open(\"model_1.json\",'w') as f:\n",
    "    f.write(model.to_json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adadecd",
   "metadata": {},
   "source": [
    "<h3>Predict tail-like regions in new sequences using model_1</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "94f7daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read model\n",
    "model = HiddenMarkovModel.from_json('model_1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "ad40bbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1353 new sequences.\n"
     ]
    }
   ],
   "source": [
    "### Get new sequences for which predictions will be generated\n",
    "\n",
    "filelist = [\n",
    "#'adk_cdhit90.fasta',\n",
    "'hbha_cdhit90.fasta',\n",
    "'hc1_cdhit90.fasta',\n",
    "'hc2_cdhit90.fasta',\n",
    "#'hu_cdhit90.fasta'\n",
    "'ku_cdhit90.fasta',\n",
    "#'l22_cdhit90.fasta',\n",
    "#'rbr_cdhit90.fasta',#? Manually identified tails are probably not correct PAK tails.\n",
    "#'sig_cdhit90.fasta',#? Manually identified tails are probably not correct PAK tails.\n",
    "#'tig_cdhit90.fasta',\n",
    "#'topo1_cdhit90.fasta',\n",
    "#'topo3_cdhit90.fasta'\n",
    "]\n",
    "new_seqs = get_seq_dictionary(datadir=datadir, filelist=full_seq_files, header_regex_str='>(.+?)\\s.*\\n', translation_dict=aa_code_cat_dict, verbose=True)\n",
    "\n",
    "#seq_tail = get_seq_dictionary(datadir=datadir, filelist=tail_seq_files, header_regex_str='>(.+).*\\n', translation_dict=aa_code_cat_dict, verbose=True)\n",
    "#seq_full = get_seq_dictionary(datadir=datadir, filelist=full_seq_files, header_regex_str='>(.+?)\\s.*\\n', translation_dict=aa_code_cat_dict, verbose=True)\n",
    "#print(\"Number of tail sequences:\",len(seq_tail),\"\\nNumber of all (full) sequences:\",len(seq_full))\n",
    "\n",
    "print(\"Found\",len(new_seqs),\"new sequences.\")\n",
    "#seqs = pd.Series(new_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "b66318db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1353, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HEADER</th>\n",
       "      <th>START</th>\n",
       "      <th>END</th>\n",
       "      <th>LEN</th>\n",
       "      <th>SEQ</th>\n",
       "      <th>LABEL_SEQ</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>DATASET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr|A0A064BZG4|A0A064BZG4_STREE</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>OAOKOOOOAKOAOATOOTKKOOAAAOOAOOAAOAOOOAAOOKOOOO...</td>\n",
       "      <td>FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...</td>\n",
       "      <td>F</td>\n",
       "      <td>NEW_SEQS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|O33125|DBH_MYCLE</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>OOKAOOOOOOTOKOOOOOOOATAAOOOOOOTOOOAOOKOOOOTOTO...</td>\n",
       "      <td>FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...</td>\n",
       "      <td>F</td>\n",
       "      <td>NEW_SEQS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|O33125|DBH_MYCLE</td>\n",
       "      <td>109</td>\n",
       "      <td>194</td>\n",
       "      <td>85</td>\n",
       "      <td>AAKKAAOKKAPOKKAOAKKAATKAPAKKAOKAPAKKOTTAOKOPAK...</td>\n",
       "      <td>TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT...</td>\n",
       "      <td>T</td>\n",
       "      <td>NEW_SEQS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|O33125|DBH_MYCLE</td>\n",
       "      <td>194</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>AKOOOK</td>\n",
       "      <td>FFFFFF</td>\n",
       "      <td>F</td>\n",
       "      <td>NEW_SEQS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|P0A1R8|DBHB_SALTY</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>OOKOOOOOKOAAOAOOOKAAAOOAOOAOOAOOTOOOKOOOOOAOOO...</td>\n",
       "      <td>FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...</td>\n",
       "      <td>F</td>\n",
       "      <td>NEW_SEQS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           HEADER START  END  LEN  \\\n",
       "0  tr|A0A064BZG4|A0A064BZG4_STREE     0   91   91   \n",
       "1             sp|O33125|DBH_MYCLE     0  109  109   \n",
       "2             sp|O33125|DBH_MYCLE   109  194   85   \n",
       "3             sp|O33125|DBH_MYCLE   194  200    6   \n",
       "4            sp|P0A1R8|DBHB_SALTY     0   90   90   \n",
       "\n",
       "                                                 SEQ  \\\n",
       "0  OAOKOOOOAKOAOATOOTKKOOAAAOOAOOAAOAOOOAAOOKOOOO...   \n",
       "1  OOKAOOOOOOTOKOOOOOOOATAAOOOOOOTOOOAOOKOOOOTOTO...   \n",
       "2  AAKKAAOKKAPOKKAOAKKAATKAPAKKAOKAPAKKOTTAOKOPAK...   \n",
       "3                                             AKOOOK   \n",
       "4  OOKOOOOOKOAAOAOOOKAAAOOAOOAOOAOOTOOOKOOOOOAOOO...   \n",
       "\n",
       "                                           LABEL_SEQ LABEL   DATASET  \n",
       "0  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...     F  NEW_SEQS  \n",
       "1  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...     F  NEW_SEQS  \n",
       "2  TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT...     T  NEW_SEQS  \n",
       "3                                             FFFFFF     F  NEW_SEQS  \n",
       "4  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...     F  NEW_SEQS  "
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Generate a dataframe from new sequences\n",
    "### Note that the LABEL_SEQ here is the predicted label sequence, because we do not know the true labels.\n",
    "\n",
    "df_new = pd.DataFrame(columns=['HEADER','START','END','LEN','SEQ','LABEL_SEQ','LABEL','DATASET'])\n",
    "\n",
    "for header in new_seqs:\n",
    "  seq = new_seqs[header]\n",
    "  pred = model.predict(list(seq))\n",
    "  pred_seq = \"\".join([states[i] for i in pred])\n",
    "\n",
    "  # For testing\n",
    "  \"\"\"\n",
    "  seq = \"AABABDBADBBADBRRRRRRBB\"\n",
    "  pred_seq = \"TTFFFFTTTFFFFFTFFTTTTT\"\n",
    "  print(seq)\n",
    "  print(pred_seq)\n",
    "\n",
    "  print(len(pred_seq),len(seq))\n",
    "  \"\"\"\n",
    "  \n",
    "  start = 0\n",
    "\n",
    "  for substr in [match[0] for match in re.findall(r'((\\w)\\2{0,})', pred_seq)]:\n",
    "    ### This regex also works: [match[0] for match in re.findall(r'((.)\\2{,})', pred_seq)]\n",
    "    end = start+len(substr)\n",
    "\n",
    "    # For testing\n",
    "    \"\"\"\n",
    "    print(substr) # For testing\n",
    "    print(start,end)\n",
    "    print(header,start,end,seq[start:end],pred_seq[start:end],'NEW_SEQS')\n",
    "    \"\"\"\n",
    "\n",
    "    df_new = pd.concat([df_new,\n",
    "                        pd.DataFrame([(header, start, end, end-start,\n",
    "                                       seq[start:end], pred_seq[start:end],\n",
    "                                       pred_seq[start], 'NEW_SEQS')],\n",
    "                                       columns=['HEADER','START','END','LEN','SEQ','LABEL_SEQ','LABEL','DATASET']\n",
    "                                    )\n",
    "                       ],\n",
    "                       ignore_index=True)\n",
    "\n",
    "    start += len(substr)\n",
    "\n",
    "print(df.shape)\n",
    "df_new.head()\n",
    "#new_seq_df[new_seq_df.LABEL == 'F']['LEN'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "59526d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-355-77240575e3e5>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['DATASET'].iloc[train_seqs.index] = 'TRAIN'\n",
      "<ipython-input-355-77240575e3e5>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['DATASET'].iloc[test_seqs.index] = 'TEST'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HEADER</th>\n",
       "      <th>START</th>\n",
       "      <th>END</th>\n",
       "      <th>LEN</th>\n",
       "      <th>SEQ</th>\n",
       "      <th>LABEL_SEQ</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>DATASET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp|O33125|DBH_MYCLE</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>OOKAOOOOOOTOKOOOOOOOATAAOOOOOOTOOOAOOKOOOOTOTO...</td>\n",
       "      <td>FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...</td>\n",
       "      <td>F</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|O33125|DBH_MYCLE</td>\n",
       "      <td>89</td>\n",
       "      <td>200</td>\n",
       "      <td>111</td>\n",
       "      <td>AOAOOOPOOOPAOKOOOATOAAKKAAOKKAPOKKAOAKKAATKAPA...</td>\n",
       "      <td>TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT...</td>\n",
       "      <td>T</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|P02348|DBH5_RHILE</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>OOKOOOOOAOAOKAOOTKOOAAOAOOAOOOOOOAOOKOKOOOOOAO...</td>\n",
       "      <td>FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...</td>\n",
       "      <td>F</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|P05384|DBHB_PSEAE</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>OOKOOOOOAOAAOAOOPKAOAOOAOOAOOOOOTOAOKAOOOOOOOO...</td>\n",
       "      <td>FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...</td>\n",
       "      <td>F</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|P0A1R8|DBHB_SALTY</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>OOKOOOOOKOAAOAOOOKAAAOOAOOAOOAOOTOOOKOOOOOAOOO...</td>\n",
       "      <td>FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...</td>\n",
       "      <td>F</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 HEADER START  END  LEN  \\\n",
       "0   sp|O33125|DBH_MYCLE     0   89   89   \n",
       "1   sp|O33125|DBH_MYCLE    89  200  111   \n",
       "2  sp|P02348|DBH5_RHILE     0   91   91   \n",
       "3  sp|P05384|DBHB_PSEAE     0   90   90   \n",
       "4  sp|P0A1R8|DBHB_SALTY     0   90   90   \n",
       "\n",
       "                                                 SEQ  \\\n",
       "0  OOKAOOOOOOTOKOOOOOOOATAAOOOOOOTOOOAOOKOOOOTOTO...   \n",
       "1  AOAOOOPOOOPAOKOOOATOAAKKAAOKKAPOKKAOAKKAATKAPA...   \n",
       "2  OOKOOOOOAOAOKAOOTKOOAAOAOOAOOOOOOAOOKOKOOOOOAO...   \n",
       "3  OOKOOOOOAOAAOAOOPKAOAOOAOOAOOOOOTOAOKAOOOOOOOO...   \n",
       "4  OOKOOOOOKOAAOAOOOKAAAOOAOOAOOAOOTOOOKOOOOOAOOO...   \n",
       "\n",
       "                                           LABEL_SEQ LABEL DATASET  \n",
       "0  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...     F    TEST  \n",
       "1  TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT...     T    TEST  \n",
       "2  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...     F    TEST  \n",
       "3  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...     F    TEST  \n",
       "4  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...     F    TEST  "
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### ADD a column to train/test data (i.e. Dataframe df) to hold dataset name.\n",
    "### Remeber that df was the dataframe where we have loaded input sequences before.\n",
    "### This is done so that we can concatanate the dataframes containing new sequences and the train/test sequences.\n",
    "\n",
    "df['DATASET'] = ''\n",
    "# Assign 'TRAIN' and 'TEST' for the sequences that are in train_seqs and test_seqs respectively.\n",
    "df['DATASET'].iloc[train_seqs.index] = 'TRAIN'\n",
    "df['DATASET'].iloc[test_seqs.index] = 'TEST'\n",
    "\n",
    "#print(df['DATASET'].value_counts())\n",
    "#print(train_seqs.shape,test_seqs.shape)\n",
    "#print(df[df['DATASET']=='TRAIN'].head())\n",
    "#print(\"Columns in df:\",df.columns)\n",
    "#print(df['DATASET'].value_counts())\n",
    "\n",
    "### Create temporary dataframe in required format\n",
    "df_train_test = pd.DataFrame(columns=['HEADER','START','END','LEN','SEQ','LABEL_SEQ','LABEL','DATASET'])\n",
    "\n",
    "for i in df.index:\n",
    "  #print(df.iloc[i])\n",
    "  row = df.iloc[i]\n",
    "  start = 0\n",
    "  for substr in [match[0] for match in re.findall(r'((\\w)\\2{0,})', row['FULLLABELS'])]:\n",
    "    end = start+len(substr)\n",
    "\n",
    "    #print(\"*\",substr)\n",
    "    #print(start,end)\n",
    "\n",
    "    df_train_test = pd.concat([df_train_test,\n",
    "                               pd.DataFrame([(row['HEADER'], start, end, end-start,\n",
    "                                              row['FULL'][start:end], row['FULLLABELS'][start:end],\n",
    "                                              row['FULLLABELS'][start], row['DATASET'])],\n",
    "                                              columns=['HEADER','START','END','LEN','SEQ','LABEL_SEQ','LABEL','DATASET']\n",
    "                                           )\n",
    "                              ],\n",
    "                              ignore_index=True)\n",
    "\n",
    "    start += len(substr)\n",
    "  \n",
    "df_train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "80af8eb8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['HEADER', 'START', 'END', 'LEN', 'SEQ', 'LABEL_SEQ', 'LABEL',\n",
      "       'DATASET'],\n",
      "      dtype='object')\n",
      "Index(['HEADER', 'START', 'END', 'LEN', 'SEQ', 'LABEL_SEQ', 'LABEL',\n",
      "       'DATASET'],\n",
      "      dtype='object')\n",
      "NEW_SEQS    1465\n",
      "TRAIN        847\n",
      "TEST         565\n",
      "Name: DATASET, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HEADER</th>\n",
       "      <th>START</th>\n",
       "      <th>END</th>\n",
       "      <th>LEN</th>\n",
       "      <th>SEQ</th>\n",
       "      <th>LABEL_SEQ</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>DATASET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp|O33125|DBH_MYCLE</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>OOKAOOOOOOTOKOOOOOOOATAAOOOOOOTOOOAOOKOOOOTOTO...</td>\n",
       "      <td>FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...</td>\n",
       "      <td>F</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp|O33125|DBH_MYCLE</td>\n",
       "      <td>89</td>\n",
       "      <td>200</td>\n",
       "      <td>111</td>\n",
       "      <td>AOAOOOPOOOPAOKOOOATOAAKKAAOKKAPOKKAOAKKAATKAPA...</td>\n",
       "      <td>TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT...</td>\n",
       "      <td>T</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp|P02348|DBH5_RHILE</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>OOKOOOOOAOAOKAOOTKOOAAOAOOAOOOOOOAOOKOKOOOOOAO...</td>\n",
       "      <td>FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...</td>\n",
       "      <td>F</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp|P05384|DBHB_PSEAE</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>OOKOOOOOAOAAOAOOPKAOAOOAOOAOOOOOTOAOKAOOOOOOOO...</td>\n",
       "      <td>FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...</td>\n",
       "      <td>F</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp|P0A1R8|DBHB_SALTY</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>OOKOOOOOKOAAOAOOOKAAAOOAOOAOOAOOTOOOKOOOOOAOOO...</td>\n",
       "      <td>FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...</td>\n",
       "      <td>F</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 HEADER START  END  LEN  \\\n",
       "0   sp|O33125|DBH_MYCLE     0   89   89   \n",
       "1   sp|O33125|DBH_MYCLE    89  200  111   \n",
       "2  sp|P02348|DBH5_RHILE     0   91   91   \n",
       "3  sp|P05384|DBHB_PSEAE     0   90   90   \n",
       "4  sp|P0A1R8|DBHB_SALTY     0   90   90   \n",
       "\n",
       "                                                 SEQ  \\\n",
       "0  OOKAOOOOOOTOKOOOOOOOATAAOOOOOOTOOOAOOKOOOOTOTO...   \n",
       "1  AOAOOOPOOOPAOKOOOATOAAKKAAOKKAPOKKAOAKKAATKAPA...   \n",
       "2  OOKOOOOOAOAOKAOOTKOOAAOAOOAOOOOOOAOOKOKOOOOOAO...   \n",
       "3  OOKOOOOOAOAAOAOOPKAOAOOAOOAOOOOOTOAOKAOOOOOOOO...   \n",
       "4  OOKOOOOOKOAAOAOOOKAAAOOAOOAOOAOOTOOOKOOOOOAOOO...   \n",
       "\n",
       "                                           LABEL_SEQ LABEL DATASET  \n",
       "0  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...     F    TEST  \n",
       "1  TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT...     T    TEST  \n",
       "2  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...     F    TEST  \n",
       "3  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...     F    TEST  \n",
       "4  FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF...     F    TEST  "
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Concatanate dataframes for new sequences and train/test dataset\n",
    "### This new dataframe with train, test and new sequences can be used to perform analyses.\n",
    "\n",
    "# Confirm that both dataframes have same columns\n",
    "print(df_train_test.columns)\n",
    "print(df_new.columns)\n",
    "\n",
    "df_train_test_new = pd.concat([df_train_test, df_new], axis=0, ignore_index=True)\n",
    "\n",
    "# Check value counts for train, test and new sequences\n",
    "print(df_train_test_new['DATASET'].value_counts())\n",
    "df_train_test_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c894019",
   "metadata": {},
   "source": [
    "### Add new variables for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "c0756d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>DATASET</th>\n",
       "      <th>P_FREQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>NEW_SEQS</td>\n",
       "      <td>0.033117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>TEST</td>\n",
       "      <td>0.032536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>0.033165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T</td>\n",
       "      <td>NEW_SEQS</td>\n",
       "      <td>0.066870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T</td>\n",
       "      <td>TEST</td>\n",
       "      <td>0.077562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T</td>\n",
       "      <td>TRAIN</td>\n",
       "      <td>0.068841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LABEL   DATASET    P_FREQ\n",
       "0     F  NEW_SEQS  0.033117\n",
       "1     F      TEST  0.032536\n",
       "2     F     TRAIN  0.033165\n",
       "3     T  NEW_SEQS  0.066870\n",
       "4     T      TEST  0.077562\n",
       "5     T     TRAIN  0.068841"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Add new variables\n",
    "#df['Discounted_Price'] = df.apply(lambda row: row.Cost - (row.Cost * 0.1), axis = 1)\n",
    "\n",
    "# Add frequency of amino acids in the amino acid categories\n",
    "for aa in aa_code_cat:\n",
    "  if aa != \"X\":\n",
    "    df_train_test_new[aa+'_FREQ'] = df_train_test_new.apply(lambda row: row['SEQ'].count(aa)/row['LEN'], axis = 1)\n",
    "\n",
    "#df_train_test_new.head()\n",
    "\n",
    "df_train_test_new[['DATASET','LABEL','P_FREQ']].groupby(by=['LABEL','DATASET'], as_index=False).agg({'P_FREQ':np.mean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "bb579d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P 0.07224060911520556\n",
      "A 0.3337805648134453\n",
      "K 0.2611259160067202\n",
      "T 0.16767301827400496\n",
      "O 0.16517989179062395\n"
     ]
    }
   ],
   "source": [
    "# Check frequencies of different amino acid categories\n",
    "for aa in aa_code_cat:\n",
    "  if aa != \"X\":\n",
    "    print(aa,df_train_test_new[(df_train_test_new['DATASET'] != 'NEW_SEQS') &\n",
    "                               (df_train_test_new['LABEL'] == 'T')][aa+'_FREQ'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "17b55724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    69.000000\n",
      "mean      0.066870\n",
      "std       0.042590\n",
      "min       0.000000\n",
      "25%       0.038095\n",
      "50%       0.061856\n",
      "75%       0.090323\n",
      "max       0.200000\n",
      "Name: P_FREQ, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: ylabel='Frequency'>"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAAsTAAALEwEAmpwYAAASTUlEQVR4nO3de5AlZX3G8e8DCHiLQBiNguuAZTAoKGTQVCxjBI0oEUg0ChHjhXJNNIlGq3QRE1OpsgrLJGhiEt14wSteiBgSNBFRtFIF4i6gAgZBWJWLskoSEAmI/vLH6TWHcWb3zOx0n519v5+qU9P9dp9+f/Q5PPtO9znvpKqQJLVjl2kXIEkalsEvSY0x+CWpMQa/JDXG4Jekxuw27QImse+++9bs7Oy0y5CkVWXjxo3fq6qZ+e2rIvhnZ2fZsGHDtMuQpFUlyTcXavdSjyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNWZVfHNXSzO77typ9LvptGOm0q+kpXHEL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9Jjekt+JO8O8nNSS5fYNurk1SSffvqX5K0sD5H/GcAR89vTPJQ4DeAb/XYtyRpEb0Ff1V9AbhlgU2nA68Bqq++JUmLG/Qaf5LjgBuq6stD9itJ+n+Dzc6Z5D7A6xhd5plk/7XAWoA1a9b0WJkktWXIEf/DgQOALyfZBOwPXJLkFxbauarWV9VcVc3NzMwMWKYk7dwGG/FX1VeBB25Z78J/rqq+N1QNkqR+P855JnAhcFCS65Oc3FdfkqTJ9Tbir6oTt7F9tq++JUmL85u7ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYMNmVDi2bXnTvtEgY1zf/eTacdM7W+pdXGEb8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4JekxvT5x9bfneTmJJePtb05yX8m+UqSs5Ps1Vf/kqSF9TniPwM4el7becCjq+pQ4OvAKT32L0laQG/BX1VfAG6Z1/bpqrq7W70I2L+v/iVJC5vmNf4XA59abGOStUk2JNmwefPmAcuSpJ3bVII/yanA3cAHF9unqtZX1VxVzc3MzAxXnCTt5Aafjz/JC4HfBI6qqhq6f0lq3aDBn+Ro4DXAk6rqh0P2LUka6fPjnGcCFwIHJbk+ycnA24D7A+cluSzJ2/vqX5K0sN5G/FV14gLN7+qrP0nSZPzmriQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktSYPv/Y+ruT3Jzk8rG2fZKcl+Tq7ufeffUvSVpYnyP+M4Cj57WtA86vqkcA53frkqQB9Rb8VfUF4JZ5zccB7+2W3wsc31f/kqSFDX2N/0FVdVO3/B3gQYvtmGRtkg1JNmzevHmY6iSpAVO7uVtVBdRWtq+vqrmqmpuZmRmwMknauQ0d/N9N8mCA7ufNA/cvSc0bOvjPAV7QLb8A+OeB+5ek5vX5cc4zgQuBg5Jcn+Rk4DTgqUmuBp7SrUuSBrRbXweuqhMX2XRUX31KkrZtohF/kkP6LkSSNIxJL/X8fZKLk7wsyQN6rUiS1KuJgr+qngg8D3gosDHJh5I8tdfKJEm9mPjmblVdDbweeC3wJOBvkvxnkt/uqzhJ0sqb9Br/oUlOB74GHAk8s6p+qVs+vcf6JEkrbNJP9fwt8E7gdVV1x5bGqroxyet7qUyS1ItJg/8Y4I6q+jFAkl2APavqh1X1/t6qkyStuEmv8X8GuPfY+n26NknSKjPpiH/PqvrBlpWq+kGS+/RUk7Rks+vOnUq/m047Zir9Sttj0hH/7UkO37KS5JeBO7ayvyRpBzXpiP+VwMeS3AgE+AXguX0VJUnqz0TBX1VfSvJI4KCu6aqq+lF/ZUmS+rKUSdqOAGa75xyehKp6Xy9VSZJ6M1HwJ3k/8HDgMuDHXXMBBr8krTKTjvjngIO7P5coSVrFJv1Uz+WMbuhKkla5SUf8+wJXJrkYuHNLY1Ud20tVkqTeTBr8f95nEZKk4Uw6H//ngU3AvbrlLwGXLLfTJH+S5Ioklyc5M8meyz2WJGlpJp2W+SXAWcA7uqb9gE8sp8Mk+wF/DMxV1aOBXYETlnMsSdLSTXpz9+XAE4Bb4ad/lOWB29HvbsC9k+zGaMK3G7fjWJKkJZg0+O+sqru2rHSBvayPdlbVDcBfAt8CbgL+p6o+PX+/JGuTbEiyYfPmzcvpSpK0gEmD//NJXsdolP5U4GPAvyynwyR7A8cBBwAPAe6b5KT5+1XV+qqaq6q5mZmZ5XQlSVrApMG/DtgMfBV4KfBJRn9/dzmeAlxXVZu7+X4+DvzqMo8lSVqiSSdp+wnwj91je30L+JVuPv87gKOADStwXEnSBCadq+c6FrimX1UHLrXDqvpikrMYfRz0buBSYP1SjyNJWp6lzNWzxZ7A7wD7LLfTqnoD8IblPl+StHyTfoHr+2OPG6rqLYz+ALskaZWZ9FLP4WOruzD6DWApc/lLknYQk4b3X40t381o+obnrHg1kqTeTfqpnif3XYgkaRiTXup51da2V9Vfr0w5kqS+LeVTPUcA53TrzwQuBq7uoyhJUn8mDf79gcOr6jaAJH8OnFtVPzPVgiRpxzbplA0PAu4aW7+ra5MkrTKTjvjfB1yc5Oxu/Xjgvb1UJK0is+vOnVrfm07zqzRankk/1fPGJJ8Cntg1vaiqLu2vLElSXya91AOjP5hya1W9Fbg+yQE91SRJ6tGkf3rxDcBrgVO6pnsBH+irKElSfyYd8f8WcCxwO0BV3Qjcv6+iJEn9mTT476qqopuaOcl9+ytJktSnSYP/o0neAeyV5CXAZ1iZP8oiSRrYNj/VkyTAR4BHArcCBwF/VlXn9VybJKkH2wz+qqokn6yqQwDDXpJWuUkv9VyS5IheK5EkDWLSb+4+HjgpySZGn+wJo18GDu2rMElSP7Ya/EnWVNW3gKetZKdJ9gLeCTya0SeFXlxVF65kH5KkhW1rxP8JRrNyfjPJP1XVs1ao37cC/1ZVz06yO6NvBUuSBrCt4M/Y8oEr0WGSBwC/BrwQoKru4p4zf0qSerSt4K9FlrfHAcBm4D1JHgNsBF5RVbeP75RkLbAWYM2aNcvubJqzJ0rSjmhbn+p5TJJbk9wGHNot35rktiS3LrPP3YDDgX+oqsMY3SxeN3+nqlpfVXNVNTczM7PMriRJ8211xF9Vu/bQ5/XA9VX1xW79LBYIfklSP5YyLfOKqKrvAN9OclDXdBRw5dB1SFKrJv0c/0r7I+CD3Sd6rgVeNKU6JKk5Uwn+qroMmJtG35LUusEv9UiSpsvgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMZMLfiT7Jrk0iT/Oq0aJKlF0xzxvwL42hT7l6QmTSX4k+wPHAO8cxr9S1LLpjXifwvwGuAnU+pfkpo1ePAn+U3g5qrauI391ibZkGTD5s2bB6pOknZ+0xjxPwE4Nskm4MPAkUk+MH+nqlpfVXNVNTczMzN0jZK00xo8+KvqlKrav6pmgROAz1bVSUPXIUmt8nP8ktSY3abZeVVdAFwwzRokqTWO+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNmeoXuCStPrPrzp1a35tOO2Zqfe9MHPFLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaszgwZ/koUk+l+TKJFckecXQNUhSy6YxV8/dwKur6pIk9wc2Jjmvqq6cQi2S1JzBR/xVdVNVXdIt3wZ8Ddhv6DokqVVTnZ0zySxwGPDFBbatBdYCrFmzZtjCJGnMzjYj6dRu7ia5H/BPwCur6tb526tqfVXNVdXczMzM8AVK0k5qKsGf5F6MQv+DVfXxadQgSa2axqd6ArwL+FpV/fXQ/UtS66Yx4n8C8HzgyCSXdY9nTKEOSWrS4Dd3q+o/gAzdryRpxG/uSlJjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhoz1dk5JS3fNGeM1OrmiF+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSY6YS/EmOTnJVkmuSrJtGDZLUqsGDP8muwN8BTwcOBk5McvDQdUhSq6Yx4n8ccE1VXVtVdwEfBo6bQh2S1KRpzM65H/DtsfXrgcfP3ynJWmBtt/qDJFcts799ge8t87l9sq6lsa6l2SnryptWsJJ72lHPF3nTdtX2sIUad9hpmatqPbB+e4+TZENVza1ASSvKupbGupbGupZmR60L+qltGpd6bgAeOra+f9cmSRrANIL/S8AjkhyQZHfgBOCcKdQhSU0a/FJPVd2d5A+Bfwd2Bd5dVVf02OV2Xy7qiXUtjXUtjXUtzY5aF/RQW6pqpY8pSdqB+c1dSWqMwS9JjVl1wb+t6R6S7JHkI932LyaZHdt2Std+VZKnTXrMPutK8tQkG5N8tft55NhzLuiOeVn3eOCAdc0muWOs77ePPeeXu3qvSfI3STJgXc8bq+myJD9J8thu2xDn69eSXJLk7iTPnrftBUmu7h4vGGsf4nwtWFeSxya5MMkVSb6S5Llj285Ict3Y+XrsUHV123481vc5Y+0HdK/5Nd17YPeh6kry5Hnvr/9Ncny3bYjz9aokV3av1flJHja2beXeX1W1ah6MbgZ/AzgQ2B34MnDwvH1eBry9Wz4B+Ei3fHC3/x7AAd1xdp3kmD3XdRjwkG750cANY8+5AJib0vmaBS5f5LgXA78CBPgU8PSh6pq3zyHANwY+X7PAocD7gGePte8DXNv93Ltb3nvA87VYXb8IPKJbfghwE7BXt37G+L5Dnq9u2w8WOe5HgRO65bcDfzBkXfNe01uA+wx4vp481t8f8P//P67o+2u1jfgnme7hOOC93fJZwFHdv4DHAR+uqjur6jrgmu54KzGFxLLrqqpLq+rGrv0K4N5J9lhi/yte12IHTPJg4Oeq6qIaveveBxw/pbpO7J67UrZZV1VtqqqvAD+Z99ynAedV1S1V9V/AecDRQ52vxeqqqq9X1dXd8o3AzcDMEvtf8boW073GRzJ6zWH0Hjh+SnU9G/hUVf1wif1vT12fG+vvIkbfc4IVfn+ttuBfaLqH/Rbbp6ruBv4H+PmtPHeSY/ZZ17hnAZdU1Z1jbe/pfq3802VcItjeug5IcmmSzyd54tj+12/jmH3XtcVzgTPntfV9vpb63KHO1zYleRyjkeY3xprf2F1WOH0ZA47trWvPJBuSXLTlcgqj1/i/u9d8Ocdcibq2OIGffX8Neb5OZjSC39pzl/X+Wm3Bv9NK8ijgTcBLx5qfV1WHAE/sHs8fsKSbgDVVdRjwKuBDSX5uwP63KsnjgR9W1eVjzdM8Xzu0bmT4fuBFVbVllHsK8EjgCEaXEF47cFkPq9FUBL8LvCXJwwfuf1Hd+TqE0feNthjsfCU5CZgD3tzH8Vdb8E8y3cNP90myG/AA4Ptbee5KTCGxPXWRZH/gbOD3quqno7GquqH7eRvwIUa/Kg5SV3dJ7Ptd/xsZjRJ/sdt//7HnD36+Oj8zGhvofC31uUOdr0V1/2CfC5xaVRdtaa+qm2rkTuA9DHu+xl+vaxndnzmM0Wu8V/eaL/mYK1FX5znA2VX1o7F6BzlfSZ4CnAocO/bb/8q+v5Z7o2IaD0bfNL6W0c3ZLTdHHjVvn5dzz5uCH+2WH8U9b+5ey+hmyzaP2XNde3X7//YCx9y3W74Xo2uevz9gXTPArt3ygd2baZ9a+GbSM4aqq1vfpavnwKHP19i+Z/CzN3evY3Tjbe9uebDztZW6dgfOB165wL4P7n4GeAtw2oB17Q3s0S3vC1xNd6MT+Bj3vLn7sqHqGmu/CHjy0OeL0T9+36C7Id/X+2vioneUB/AM4OvdyTm1a/sLRv86AuzZvXGu6U7IeDic2j3vKsbufC90zKHqAl4P3A5cNvZ4IHBfYCPwFUY3fd9KF8QD1fWsrt/LgEuAZ44dcw64vDvm2+i+AT7g6/jrwEXzjjfU+TqC0XXU2xmNTq8Ye+6Lu3qvYXRJZcjztWBdwEnAj+a9vx7bbfss8NWutg8A9xuwrl/t+v5y9/PksWMe2L3m13TvgT0Gfh1nGQ0sdpl3zCHO12eA7469Vuf08f5yygZJasxqu8YvSdpOBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqzP8BqxOu6ECnVzkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Frequency of P in NEW_SEQS tail regions\n",
    "print(df_train_test_new[(df_train_test_new['DATASET'] == 'NEW_SEQS') & (df_train_test_new['LABEL'] == 'T')].P_FREQ.describe())\n",
    "df_train_test_new[(df_train_test_new['DATASET'] == 'NEW_SEQS') & (df_train_test_new['LABEL'] == 'T')].P_FREQ.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "20a55522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    59.000000\n",
      "mean      0.072241\n",
      "std       0.032990\n",
      "min       0.017857\n",
      "25%       0.051109\n",
      "50%       0.066176\n",
      "75%       0.086164\n",
      "max       0.202128\n",
      "Name: P_FREQ, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: ylabel='Frequency'>"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Frequency of P in TRAIN and TEST sequences tail regions\n",
    "print(df_train_test_new[(df_train_test_new['DATASET'] != 'NEW_SEQS') & (df_train_test_new['LABEL'] == 'T')].P_FREQ.describe())\n",
    "df_train_test_new[(df_train_test_new['DATASET'] != 'NEW_SEQS') & (df_train_test_new['LABEL'] == 'T')].P_FREQ.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d239bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcf3598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcf24fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmm-annotate-sequence",
   "language": "python",
   "name": "hmm-annotate-sequence"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
